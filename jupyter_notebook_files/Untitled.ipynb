{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f9b1e1e",
   "metadata": {},
   "source": [
    "# Golden redfish model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc1f12",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains the python code for the Golden redfish model that Maris Optimum has developed.\n",
    "Sources:\n",
    "    Data from Icelandic Marine and freshwater institute (1)\n",
    "    It uses the gradient boosting regression algorithm xgboost (2) and various packages (2)\n",
    "    It is written in the python programming language\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26f1ad",
   "metadata": {},
   "source": [
    "### Packages imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e73957c",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "# import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca2b13",
   "metadata": {},
   "source": [
    "### Conversion of kg catch to unit of fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661a9918",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def catch_converter(X_catch_per_df, catch_df):\n",
    "    \"\"\"\n",
    "    Catch information used to formulate units from kg.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_catch_per_df : Dataframe containing percentages of catch\n",
    "    catch_df : Dataframe containing total cath in kg\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    catch_df : Dataframe containing total catch in lengths\n",
    "    \"\"\"\n",
    "    path_grs_str = 'R:/Ráðgjöf/Maris Optimum/Golden_redfish_model/'\n",
    "    wl_df = pd.read_csv(path_grs_str+'RED_gadget_n_at_age.csv', sep=',')\n",
    "    Xl = wl_df[['year', 'mean_length']]\n",
    "    yl = wl_df[['year', 'mean_weight']]\n",
    "    for index, row in Xl.iterrows():\n",
    "        Xl.at[index, 'squared'] = row[1]**2\n",
    "\n",
    "    for year in range(1985, 2022):\n",
    "        average_weight = 0\n",
    "        reg_X = Xl[Xl['year'] == year]\n",
    "        reg_y = yl[yl['year'] == year]\n",
    "        reg = LinearRegression().fit(\n",
    "            reg_X[['mean_length', 'squared']], reg_y[['mean_weight']])\n",
    "        b = reg.coef_[0][0]\n",
    "        a = reg.coef_[0][1]\n",
    "        c = reg.intercept_\n",
    "        for col in range(1010, 1060):\n",
    "            average_weight += (X_catch_per_df.loc[year, str(col)]) * (\n",
    "                a*(col - 1000)**2 + b*(col - 1000) + c)\n",
    "        catch_df.at[\n",
    "            year - 1985, 'number'] = catch_df.loc[\n",
    "                year - 1985, 'catch']/average_weight\n",
    "    return catch_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef8e1c7",
   "metadata": {},
   "source": [
    "### Data fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dddd224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_data(fractile):\n",
    "    \"\"\"\n",
    "    Fetch all data for the regression  fetched.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fractile : integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    XX_df : Dataframe with data for all dependent variables\n",
    "    YY : Dataframe with data for the independant variable\n",
    "\n",
    "    \"\"\"\n",
    "    path_str = 'R:\\\\Ráðgjöf\\\\Bláa hagkerfið\\\\Hafró\\\\distribution_output\\\\'\n",
    "    path_str_do = 'R:\\\\Ráðgjöf\\\\Maris Optimum/distribution_output\\\\'\n",
    "    X_df = pd.read_csv(path_str_do + 'distribution' + fractile + '.csv',\n",
    "                       sep=\",\")\n",
    "\n",
    "    ysq_df = X_df[['ar', 'max(cum)']]\n",
    "    ysq_df.set_index(['ar'], inplace=True)\n",
    "    ysq_df = ysq_df[~ysq_df.index.duplicated(keep='first')]\n",
    "\n",
    "    catch_df = pd.read_csv(path_str + 'golden_redfish_catch.csv',\n",
    "                           sep=\";\")\n",
    "\n",
    "    catch_df.at[37, 'year'] = 2022.0\n",
    "    catch_df.at[37, 'catch'] = 26\n",
    "    catch_df.at[37, 'number'] = 29\n",
    "\n",
    "    X_cal_df = pd.read_csv(path_str_do+'distribution_commercial.csv',\n",
    "                           sep=\",\")\n",
    "    X_cal_df.drop(1605, axis=0, inplace=True)\n",
    "\n",
    "    X_cal_df = X_cal_df.pivot(index='ar',\n",
    "                              columns='lengd',\n",
    "                              values='per_length')\n",
    "    X_cal_df = X_cal_df.fillna(0)\n",
    "    X_cal_df.columns = 1000 + X_cal_df.columns\n",
    "    X_cal_df.columns = X_cal_df.columns.astype(int).astype(str)\n",
    "\n",
    "    catch_df = catch_converter(X_cal_df, catch_df)\n",
    "    catch_df.year = catch_df.year.astype(int)\n",
    "    catch_df.set_index(catch_df.year, inplace=True)\n",
    "\n",
    "    X_cal_df = X_cal_df.mul(catch_df.number*-1e6, axis=0)\n",
    "\n",
    "    XX_df = X_df.pivot(index='ar',\n",
    "                       columns='lengd',\n",
    "                       values='per_length')\n",
    "\n",
    "    XX_df = pd.merge(XX_df, ysq_df, right_index=True, left_index=True)\n",
    "\n",
    "    # XX_df.drop(4.5, axis=1, inplace=True)\n",
    "    # XX_df.drop(6.4, axis=1, inplace=True)\n",
    "    XX_df.drop(11.9, axis=1, inplace=True)\n",
    "    XX_df.drop(12.5, axis=1, inplace=True)\n",
    "    XX_df.drop(12.6, axis=1, inplace=True)\n",
    "    XX_df.drop(13.1, axis=1, inplace=True)\n",
    "    XX_df.drop(13.4, axis=1, inplace=True)\n",
    "    XX_df.drop(13.6, axis=1, inplace=True)\n",
    "    XX_df.drop(13.7, axis=1, inplace=True)\n",
    "    XX_df.drop(13.9, axis=1, inplace=True)\n",
    "    XX_df.drop(14.4, axis=1, inplace=True)\n",
    "    XX_df.drop(14.5, axis=1, inplace=True)\n",
    "    XX_df.drop(14.7, axis=1, inplace=True)\n",
    "    XX_df.drop(14.8, axis=1, inplace=True)\n",
    "    XX_df.drop(14.9, axis=1, inplace=True)\n",
    "\n",
    "    XX_df.columns = XX_df.columns.astype(str)\n",
    "\n",
    "    YX = pd.read_csv(path_str+\"RED_numbers_at_age.csv\", sep=\";\")\n",
    "    YY = YX.iloc[15:53, 28]\n",
    "\n",
    "    XX_df = XX_df.join(X_cal_df.iloc[:, :])\n",
    "\n",
    "    XX_df.index = XX_df.index.astype(str)\n",
    "    \n",
    "    XX_df = XX_df.fillna(0)\n",
    "\n",
    "    return (XX_df, YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41a82cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot over possible result range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14119b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result_range(result_dict, interval_int, fractile, regressor_type):\n",
    "    \"\"\"\n",
    "    Plot mae and r^2 for the range of the looped regression.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_dict : a dictianary containing the results from different regression\n",
    "    over the interval.\n",
    "    interval_int : integer with the increments used over the interval\n",
    "    fractile : fractile used for Winsorization\n",
    "    regressor_type : TYPE\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    result_dict['x'] = range(343, 493, int(interval_int/1e6))\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.set(style='whitegrid',\n",
    "            palette='pastel', )\n",
    "    sns.lineplot(x='x',\n",
    "                 y='r2',\n",
    "                 data=result_dict,\n",
    "                 color=\"red\",\n",
    "                 ax=ax)\n",
    "    ax.set(xlabel='size of stock in millions',\n",
    "           ylabel='r2, red',\n",
    "           title='school fractile:'+fractile+'\\n' +\n",
    "           'regressor type :' + regressor_type + '\\n'+'1985-2022',\n",
    "           ylim=(0, 1))\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    sns.lineplot(x='x',\n",
    "                 y='mae',\n",
    "                 data=result_dict,\n",
    "                 color='blue',\n",
    "                 markers=True, ax=ax2)\n",
    "    ax2.set(ylabel='mean average error, blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9910e4f",
   "metadata": {},
   "source": [
    "### Shap calculations and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec508a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_calculations_xgb(regressor, XX_df):\n",
    "    \"\"\"\n",
    "    Calculate shap vales for the xgb_regressor and the dependant variables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    regressor : TYPE\n",
    "        DESCRIPTION.\n",
    "    XX_df : TYPE\n",
    "        DESCRIPTION.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    explainer = shap.TreeExplainer(regressor)\n",
    "\n",
    "    shap_values = explainer.shap_values(XX_df)\n",
    "\n",
    "    shap.summary_plot(shap_values,\n",
    "                      XX_df,\n",
    "                      plot_type=\"bar\",\n",
    "                      max_display=50)\n",
    "\n",
    "    shap_values = explainer(XX_df)\n",
    "    shap.waterfall_plot(shap_values[37], max_display=40)\n",
    "    shap.waterfall_plot(shap_values[35], max_display=40)\n",
    "    shap.waterfall_plot(shap_values[33], max_display=40)\n",
    "    shap.waterfall_plot(shap_values[31], max_display=40)\n",
    "    shap.waterfall_plot(shap_values[29], max_display=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3b804",
   "metadata": {},
   "source": [
    "### Regression over possible ending values of stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510fadb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_over_possible_values_XGB(X, y, interval_int):\n",
    "    \"\"\"\n",
    "    Loop over possible stock sizes, regressing in every step.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : Dataframe with dependant variables.\n",
    "    y : TDataframe with independant variables\n",
    "    interval_int : step interval.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result_dict : json string with solutions in each interval.\n",
    "\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'nthread': [0],\n",
    "        'objective': ['reg:squarederror'],\n",
    "        'eval_metric': [\"mae\"],\n",
    "        'learning_rate': [.2, .3],\n",
    "        'max_depth': [2, 3, 4],\n",
    "        'min_child_weight': [2],\n",
    "        'subsample': [0.5, 0.6],\n",
    "        'colsample_bytree': [.6, .7],\n",
    "        'n_estimators': [50]\n",
    "    }\n",
    "    test_size = .25\n",
    "    seed = 3\n",
    "    result_dict = {'fjoldi2022': [], 'fjoldi2021': [],\n",
    "                   'fjoldi2020': [], 'mae': [], 'rmse': [], 'r2': [],\n",
    "                   'evs': []}\n",
    "\n",
    "    xgb1 = xgb.XGBRegressor(seed)\n",
    "\n",
    "    for add_int in range(0, 150000000, interval_int):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=test_size,\n",
    "            random_state=seed)\n",
    "\n",
    "        X_train = pd.concat([X.iloc[:27, :], X.iloc[35:38, :]])\n",
    "        y_train = pd.concat([y.iloc[:27], y.iloc[35:38]])\n",
    "        X_test = X.iloc[27:35, :]\n",
    "        y_test = y.iloc[27:35]\n",
    "        \n",
    "        \n",
    "\n",
    "        '''\n",
    "\n",
    "        X_train = X.iloc[:30, :]\n",
    "        y_train = y.iloc[:30]\n",
    "        X_test = X.iloc[30:38, :]\n",
    "        y_test = y.iloc[30:38]\n",
    "        '''\n",
    "\n",
    "        n_iter = 200\n",
    "        n_iter = n_iter\n",
    "\n",
    "        xgb_regressor = GridSearchCV(xgb1,\n",
    "                                     parameters,\n",
    "                                     cv=2,\n",
    "                                     verbose=0)\n",
    "\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "        xgb_regressor.fit(X_train,\n",
    "                          y_train,\n",
    "                          eval_set=eval_set,\n",
    "                          verbose=False)\n",
    "\n",
    "        y_pred_test = xgb_regressor.predict(X_test)\n",
    "        print(xgb_regressor.best_params_)\n",
    "\n",
    "        result_dict['fjoldi2022'].append(y[52])\n",
    "        result_dict['fjoldi2021'].append(y[51])\n",
    "        result_dict['fjoldi2020'].append(y[50])\n",
    "\n",
    "        result_dict['mae'].append(mean_absolute_error(y_test,\n",
    "                                                      y_pred_test))\n",
    "        result_dict['rmse'].append(math.sqrt(mean_squared_error(y_test,\n",
    "                                                                y_pred_test)))\n",
    "        result_dict['r2'].append(r2_score(y_test,\n",
    "                                          y_pred_test))\n",
    "        result_dict['evs'].append(explained_variance_score(y_test,\n",
    "                                                           y_pred_test))\n",
    "        y[50] += interval_int * (y[50]/y[51])\n",
    "        y[51] += interval_int * (y[51]/y[52])\n",
    "        y[52] += interval_int\n",
    "\n",
    "    min_value = min(result_dict['mae'])\n",
    "    min_index = result_dict['mae'].index(min_value)\n",
    "\n",
    "    y[50] = result_dict['fjoldi2020'][min_index]\n",
    "    y[51] = result_dict['fjoldi2021'][min_index]\n",
    "    y[52] = result_dict['fjoldi2022'][min_index]\n",
    "\n",
    "    regressor = GridSearchCV(xgb1,\n",
    "                             parameters,\n",
    "                             cv=2,\n",
    "                             verbose=0)\n",
    "\n",
    "    regressor.fit(X, y)\n",
    "    params = regressor.best_params_\n",
    "    regressor = xgb.XGBRegressor(**params)\n",
    "    regressor.fit(X, y)\n",
    "    print(regressor.predict(X))\n",
    "\n",
    "    shap_calculations_xgb(regressor, X)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b62b8d",
   "metadata": {},
   "source": [
    "### Running code1: Using Random training sets, testing them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448e5b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.6}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.6}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.6}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.6}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.6}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.3, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.2, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n",
      "{'colsample_bytree': 0.6, 'eval_metric': 'mae', 'learning_rate': 0.3, 'max_depth': 2, 'min_child_weight': 2, 'n_estimators': 50, 'nthread': 0, 'objective': 'reg:squarederror', 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "fractile = '096'\n",
    "interval_int = 1000000\n",
    "\n",
    "(X, y) = get_new_data(fractile)\n",
    "\n",
    "result_dict_gb = regression_over_possible_values_XGB(X, y, interval_int)\n",
    "regressor_type = 'rgb'\n",
    "plot_result_range(result_dict_gb, interval_int, fractile, regressor_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001671fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
